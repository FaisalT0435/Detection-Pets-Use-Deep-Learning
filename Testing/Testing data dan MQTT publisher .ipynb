{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_jTVG4Y5t0J"
      },
      "source": [
        "IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wgw0Ps2xLly7"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import torch\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision import datasets, models\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4J5X5hzLOgs"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmAgTEVt5z-O"
      },
      "source": [
        "MENGHUBUNGKAN KE GOOGLE DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO0--upJLqXF",
        "outputId": "7c1a3ca4-3177-498b-bb77-dfb41b8a9097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkseeI1q546U"
      },
      "source": [
        "AKTIFKAN LOAD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hdr8ADTaL_Gh"
      },
      "outputs": [],
      "source": [
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "LOAD_MODEL = True\n",
        "lr=0.01\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4tN7N-Q4Yym"
      },
      "source": [
        "MEMANGGIL TIAP MODEL DARI LIBRARY "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwKl5kX644Jf"
      },
      "outputs": [],
      "source": [
        "# MEMANGGIL MODEL FASTER RCNN DARI LIBRARY \n",
        "def get_model():\n",
        "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features \n",
        "    model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=5)\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiKGQWn34qRh"
      },
      "outputs": [],
      "source": [
        "# MEMANGGIL MODEL FAST RCNN DARI LIBRARY \n",
        "def get_model():\n",
        "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features \n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=5)\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SlPktizuMJAe"
      },
      "outputs": [],
      "source": [
        "# MEMANGGIL MODEL MASK RCNN DARI LIBRARY \n",
        "def get_model():\n",
        "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
        "            in_features, num_classes=5)\n",
        "    model.to(DEVICE)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpi62wgB6Egj"
      },
      "source": [
        "MENGINISIASI MODEL DAN TUNNING "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "6f6e58820ec14285839216743bf0710a",
            "29caae1565ee41ffaa689bc3edd01a65",
            "2ef43e13169b4d37a9da642d04300ed5",
            "2e000f447bed4eb49a672654fd75d737",
            "2c0fd2cc5e5e49148ff3decdc99255ec",
            "ffb3dfc46c84492ca52331a455aa8bcb",
            "52600f544a0b4c14a6497079bd56e924",
            "239b32bbec4a4694b68d1028b0220079",
            "36beea8978fb412b90c69e70890aed6d",
            "d3643dc5378c414498af6eb70f9407da",
            "f41a1f14873e428f89fcc8fe7afaace4"
          ]
        },
        "id": "__6h14BCM3u7",
        "outputId": "7f037b0e-b9fe-4b56-a2a3-d6e2fc4c6563"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f6e58820ec14285839216743bf0710a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/170M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = get_model()\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPcpjibG6L3u"
      },
      "source": [
        "MEMBUAT FUNGSI LOAD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pFBL9kN_Nl5S"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(checkpoint, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8_B16wiMTwB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# memanggil model terbaik berdasarkan file model yang disimpan\n",
        "load_checkpoint(torch.load('/content/drive/MyDrive/Mask_RCNN/Dataset/1152KaggleBest_second_5.pth.tar'), model, optimizer, lr)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdKVfr1D6WV0"
      },
      "source": [
        "MEMBUAT FUNGSI PREDIKSI DARI MODEL YANG DI LOAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mAgeDi-oOTC1"
      },
      "outputs": [],
      "source": [
        "def predict_single_frame(frame):\n",
        "    IMAGE_SIZE = [416,416]\n",
        "    scale_percent = 60 # percent of original size\n",
        "    width = int(frame.shape[1] * scale_percent / 100)\n",
        "    height = int(frame.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "      \n",
        "    # resize image\n",
        "    images = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "    images = cv2.resize(frame, IMAGE_SIZE, cv2.INTER_LINEAR)\n",
        "    images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
        "    images = images.swapaxes(1, 3).swapaxes(2, 3)\n",
        "    images = list(image.to(DEVICE) for image in images)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      pred = model(images)\n",
        "    \n",
        "    # print(pred)\n",
        "    \n",
        "    im = images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.float32)\n",
        "    im2 = np.zeros_like(im).astype(np.float32)\n",
        "    x = \"Not Pest\"\n",
        "    for i in range(len(pred[0]['masks'])):\n",
        "        label = []\n",
        "        msk=pred[0]['masks'][i,0].detach().cpu().numpy()\n",
        "        scr=pred[0]['scores'][i].detach().cpu().numpy()\n",
        "        box=pred[0]['boxes'][i].detach().cpu().numpy()\n",
        "        lbl=pred[0]['labels'][i].detach().cpu().numpy()\n",
        "        \n",
        "        if scr>0.8 :\n",
        "            # merubah menjadi pest/hama ketika prediksi label Belalang, Ulat dan Wereng \n",
        "            if (lbl == 1) or (lbl == 3) or (lbl == 4) :\n",
        "              x = \"Pest\"\n",
        "              \n",
        "            # merubah menjadi Not pest/hama ketika prediksi sehat\n",
        "            else :\n",
        "              x = \"Not Pest\"\n",
        "            \n",
        "            cv2.rectangle(im, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0,0,1), 2)\n",
        "            cv2.putText(im, \"{0:.2f}%\".format(scr*100), (int(box[0]+10), int(box[1])+40), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.5, (0,0,1), 2, cv2.LINE_AA)\n",
        "            cv2.putText(im, x , (int(box[0]+4), int(box[1])+15), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.5, (0,0,1), 2, cv2.LINE_AA)\n",
        "            im2[:,:,0][msk>0.87] = np.random.uniform(0,1)\n",
        "            im2[:, :, 1][msk > 0.87] = np.random.uniform(0,1)\n",
        "            im2[:, :, 2][msk > 0.87] = np.random.uniform(0,1)\n",
        "\n",
        "\n",
        "      \n",
        "   \n",
        "       \n",
        "    return (cv2.addWeighted(im, 0.8, im2, 0.2,0)*255).astype(np.uint8),x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf1V_qec6fzv"
      },
      "source": [
        "MEMANGGIL SEMUA FILE GAMBAR DARI KAMERA UNTUK DI PREDIKSI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXa4jYHnHMjJ"
      },
      "outputs": [],
      "source": [
        "hasil_pre = []\n",
        "folder_dir = \"/content/drive/MyDrive/Dataset/Uji/\"\n",
        "    \n",
        "    for images in os.listdir(folder_dir):\n",
        "        \n",
        "            #  cek file format .jpg\n",
        "            if (images.endswith(\".jpg\")):\n",
        "                \n",
        "              cap = cv2.VideoCapture(folder_dir+images)\n",
        "              model.train(False)\n",
        "\n",
        "              if (cap.isOpened()== False): \n",
        "                  print(\"Error opening video stream or file\")\n",
        "\n",
        "              images = []   \n",
        "              while(cap.isOpened()):\n",
        "                  ret, frame = cap.read()\n",
        "                  if ret == True:\n",
        "                      result_frame, predict = predict_single_frame(frame)\n",
        "                      images.append(result_frame)\n",
        "                      hasil_pre.append (predict)\n",
        "                      \n",
        "                  else: \n",
        "                      break\n",
        "\n",
        "              cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92TNbRaf6ocZ"
      },
      "source": [
        "MENAMPILKAN GAMBAR HASIL PREDIKSI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY7oU0n_TRiw"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(result_frame)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Memanggil True Label Untuk menampilkan evaluasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A30skpYHNWf"
      },
      "outputs": [],
      "source": [
        "# labels = pd.read_csv('/content/drive/MyDrive/Dataset/Uji/Data Benar.csv', sep=',')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWPZ6WOjHS9w"
      },
      "outputs": [],
      "source": [
        "# def get_label(row):\n",
        "#       for c in labels.columns:\n",
        "#     if row[c]==1:\n",
        "#       return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUzy0FXqHU3B"
      },
      "outputs": [],
      "source": [
        "# test_labels = labels.apply(get_label, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtUTShUiMHKF"
      },
      "outputs": [],
      "source": [
        "# df_hasil_pred = pd.DataFrame(hasil_pre)\n",
        "# df_hasil_pred [1] = pd.DataFrame(test_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVQdIdju3sVo"
      },
      "source": [
        "HASIL EVALUASI MODEL FASTER RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyeF4WODKOQ1",
        "outputId": "14436b7c-ebaf-43f1-bea6-a6532df2a435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Belalang       1.00      1.00      1.00         3\n",
            "       Sehat       1.00      0.80      0.89         5\n",
            "        Ulat       1.00      1.00      1.00        10\n",
            "      Wereng       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        29\n",
            "   macro avg       0.98      0.95      0.96        29\n",
            "weighted avg       0.97      0.97      0.96        29\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # Faster RCNN\n",
        "\n",
        "# actual = df_hasil_pred[0]\n",
        "# predicted = df_hasil_pred[1]\n",
        "# from sklearn.metrics import classification_report\n",
        "# print(classification_report(actual, predicted, target_names=['Belalang', 'Sehat', 'Ulat', 'Wereng']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6D0l54831Ya"
      },
      "source": [
        "HASIL EVALUASI FAST RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2VLGUMMKiUH",
        "outputId": "8b02acff-8325-4069-80ff-b83dccc6eb57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Belalang       1.00      1.00      1.00         3\n",
            "       Sehat       1.00      0.67      0.80         6\n",
            "        Ulat       1.00      1.00      1.00        10\n",
            "      Wereng       0.83      1.00      0.91        10\n",
            "\n",
            "    accuracy                           0.93        29\n",
            "   macro avg       0.96      0.92      0.93        29\n",
            "weighted avg       0.94      0.93      0.93        29\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # Fast RCNN\n",
        "\n",
        "# actual = df_hasil_pred[0]\n",
        "# predicted = df_hasil_pred[1]\n",
        "# from sklearn.metrics import classification_report\n",
        "# print(classification_report(actual, predicted, target_names=['Belalang', 'Sehat', 'Ulat', 'Wereng']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcayRVUw37ng"
      },
      "source": [
        "HASIL EVALUASI MASK RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9WB-XplLGen",
        "outputId": "69955009-f6c0-4b31-f464-24cda4eb9b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Belalang       1.00      1.00      1.00         3\n",
            "       Sehat       1.00      0.50      0.67         8\n",
            "        Ulat       0.90      1.00      0.95         9\n",
            "      Wereng       0.75      1.00      0.86         9\n",
            "\n",
            "    accuracy                           0.86        29\n",
            "   macro avg       0.91      0.88      0.87        29\n",
            "weighted avg       0.89      0.86      0.85        29\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # Mask RCNN\n",
        "\n",
        "# actual = df_hasil_pred[0]\n",
        "# predicted = df_hasil_pred[1]\n",
        "# from sklearn.metrics import classification_report\n",
        "# print(classification_report(actual, predicted, target_names=['Belalang', 'Sehat', 'Ulat', 'Wereng']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i55LUboq69Tn"
      },
      "source": [
        "MENYAMBUNGKAN KE MQTT UNTUK DI PUBLISH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRDr1f-PU_hh",
        "outputId": "e64fc4e9-fa5d-4c67-f7dd-2db63c3a73d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paho-mqtt\n",
            "  Downloading paho-mqtt-1.6.1.tar.gz (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: paho-mqtt\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.6.1-py3-none-any.whl size=62132 sha256=c9db1a350a6e91fedbbc9eff996cea056837eecd5b437b68371b997a6a93699f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/48/01/c895c027e9b9367ec5470fbf371ee56e795a49ac6a19aa4c9f\n",
            "Successfully built paho-mqtt\n",
            "Installing collected packages: paho-mqtt\n",
            "Successfully installed paho-mqtt-1.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting simpy\n",
            "  Downloading simpy-4.0.1-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: simpy\n",
            "Successfully installed simpy-4.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install paho-mqtt\n",
        "!pip install simpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mqy4pIElVINn"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "from paho.mqtt import client as mqtt_client\n",
        "\n",
        "broker = 'broker.emqx.io'\n",
        "port = 1883\n",
        "topic1 = \"detect/Pest\"\n",
        "# topic0 = \"detect/healthy\"\n",
        "# generate client ID with pub prefix randomly\n",
        "client_id = f'python-mqtt-{random.randint(0, 1000)}'\n",
        "username = 'emqx'\n",
        "password = 'public'\n",
        "\n",
        "def connect_mqtt():\n",
        "    def on_connect(client, userdata, flags, rc):\n",
        "        if rc == 0:\n",
        "            print(\"Connected to MQTT Broker!\")\n",
        "        else:\n",
        "            print(\"Failed to connect, return code %d\\n\", rc)\n",
        "\n",
        "    client = mqtt_client.Client(client_id)\n",
        "    client.username_pw_set(username, password)\n",
        "    client.on_connect = on_connect\n",
        "    client.connect(broker, port)\n",
        "    return client\n",
        "\n",
        "\n",
        "def publish(client):\n",
        "    \n",
        "    msg_count = 0\n",
        "    msg = ''\n",
        "    hasil_pre = []\n",
        " \n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "\n",
        "        folder_dir = \"/content/drive/MyDrive/Mask_RCNN/Dataset/Uji/\"\n",
        "        print(os.listdir(folder_dir))\n",
        "        for images in os.listdir(folder_dir):\n",
        "        \n",
        "              cap = cv2.VideoCapture(folder_dir+images)\n",
        "              model.train(False)\n",
        "\n",
        "              if (cap.isOpened()== False): \n",
        "                  print(\"Error opening video stream or file\")\n",
        "\n",
        "              images = []   \n",
        "              while(cap.isOpened()):\n",
        "                  ret, frame = cap.read()\n",
        "                  if ret == True:\n",
        "                      result_frame, predict = predict_single_frame(frame)\n",
        "                      images.append(result_frame)\n",
        "                      hasil_pre.append (predict)\n",
        "                      # cv2_imshow(result_frame)\n",
        "                  else: \n",
        "                      break\n",
        "\n",
        "              cap.release()\n",
        "        deteksi = []\n",
        "        for i in hasil_pre:\n",
        "            if (i == 'Pest')  :\n",
        "                j = 'Pest'\n",
        "                deteksi.append(j)\n",
        "            else:\n",
        "                j = 'healthy'\n",
        "                deteksi.append(j)\n",
        "        # print (deteksi)\n",
        "    \n",
        "        for x in deteksi:\n",
        "            if (x == 'Pest'):\n",
        "                msg = \"Pest\"\n",
        "                result = client.publish(topic1, msg)\n",
        "                status = result[0]\n",
        "                if status == 0:\n",
        "                  print(f\"Send `{msg}` to topic `{topic1}`\")\n",
        "            else:\n",
        "                  print(f\"Failed to send message to topic {topic1}\")\n",
        "\n",
        "\n",
        "def run():\n",
        "    client = connect_mqtt()\n",
        "    client.loop_start()\n",
        "    publish(client)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rLTM5JzcVZH9",
        "outputId": "aee24160-e56d-4276-d9b7-e6b1b32f6c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to MQTT Broker!\n",
            "['2023-01-22_12.16.18.307.png', '2023-01-22_12.16.26.302.png', '2023-01-22_12.16.30.299.png', '2023-01-22_12.16.34.297.png', '2023-01-22_12.16.38.294.png', '2023-01-22_12.16.42.292.png', '2023-01-22_12.17.10.275.png', '272.png', '2023-01-22_12.17.14.272.png', '2023-01-22_12.17.18.269.png', '2023-01-22_12.17.22.267.png', '2023-01-22_12.17.26.264.png', '2023-01-22_12.17.30.262.png', '2023-01-22_12.17.54.246.png', '2023-01-22_12.17.58.245.png', '2023-01-22_12.18.02.242.png', '2023-01-22_12.18.06.239.png', '2023-01-22_12.18.10.236.png', '.ipynb_checkpoints', '2023-02-07_00.26.33.922.png', '2023-02-07_00.27.22.804.png', '2023-02-07_00.27.34.796.png', '2023-02-07_00.28.10.774.png', '2023-02-07_00.28.14.773.png', '2023-02-07_00.28.38.756.png', '2023-02-07_00.28.46.751.png', '2023-02-07_00.35.55.356.png', '2023-02-07_00.36.47.303.png', '2023-02-07_00.37.19.282.png', '2023-02-07_00.37.23.285.png', '2023-02-07_00.37.27.277.png']\n",
            "Connected to MQTT Broker!\n",
            "Connected to MQTT Broker!\n",
            "Error opening video stream or file\n",
            "Connected to MQTT Broker!\n",
            "Failed to send message to topic detect/Pest\n",
            "Connected to MQTT Broker!\n",
            "['2023-01-22_12.16.18.307.png', '2023-01-22_12.16.26.302.png', '2023-01-22_12.16.30.299.png', '2023-01-22_12.16.34.297.png', '2023-01-22_12.16.38.294.png', '2023-01-22_12.16.42.292.png', '2023-01-22_12.17.10.275.png', '272.png', '2023-01-22_12.17.14.272.png', '2023-01-22_12.17.18.269.png', '2023-01-22_12.17.22.267.png', '2023-01-22_12.17.26.264.png', '2023-01-22_12.17.30.262.png', '2023-01-22_12.17.54.246.png', '2023-01-22_12.17.58.245.png', '2023-01-22_12.18.02.242.png', '2023-01-22_12.18.06.239.png', '2023-01-22_12.18.10.236.png', '.ipynb_checkpoints', '2023-02-07_00.26.33.922.png', '2023-02-07_00.27.22.804.png', '2023-02-07_00.27.34.796.png', '2023-02-07_00.28.10.774.png', '2023-02-07_00.28.14.773.png', '2023-02-07_00.28.38.756.png', '2023-02-07_00.28.46.751.png', '2023-02-07_00.35.55.356.png', '2023-02-07_00.36.47.303.png', '2023-02-07_00.37.19.282.png', '2023-02-07_00.37.23.285.png', '2023-02-07_00.37.27.277.png']\n",
            "Connected to MQTT Broker!\n",
            "Error opening video stream or file\n",
            "Connected to MQTT Broker!\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Failed to send message to topic detect/Pest\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Failed to send message to topic detect/Pest\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Send `Pest` to topic `detect/Pest`\n",
            "Connected to MQTT Broker!\n",
            "['2023-01-22_12.16.18.307.png', '2023-01-22_12.16.26.302.png', '2023-01-22_12.16.30.299.png', '2023-01-22_12.16.34.297.png', '2023-01-22_12.16.38.294.png', '2023-01-22_12.16.42.292.png', '2023-01-22_12.17.10.275.png', '272.png', '2023-01-22_12.17.14.272.png', '2023-01-22_12.17.18.269.png', '2023-01-22_12.17.22.267.png', '2023-01-22_12.17.26.264.png', '2023-01-22_12.17.30.262.png', '2023-01-22_12.17.54.246.png', '2023-01-22_12.17.58.245.png', '2023-01-22_12.18.02.242.png', '2023-01-22_12.18.06.239.png', '2023-01-22_12.18.10.236.png', '.ipynb_checkpoints', '2023-02-07_00.26.33.922.png', '2023-02-07_00.27.22.804.png', '2023-02-07_00.27.34.796.png', '2023-02-07_00.28.10.774.png', '2023-02-07_00.28.14.773.png', '2023-02-07_00.28.38.756.png', '2023-02-07_00.28.46.751.png', '2023-02-07_00.35.55.356.png', '2023-02-07_00.36.47.303.png', '2023-02-07_00.37.19.282.png', '2023-02-07_00.37.23.285.png', '2023-02-07_00.37.27.277.png']\n",
            "Connected to MQTT Broker!\n",
            "Connected to MQTT Broker!\n",
            "Error opening video stream or file\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-7a8b4156a0cc>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_mqtt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-7a8b4156a0cc>\u001b[0m in \u001b[0;36mpublish\u001b[0;34m(client)\u001b[0m\n\u001b[1;32m     61\u001b[0m                   \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                   \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                       \u001b[0mresult_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_single_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                       \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                       \u001b[0mhasil_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-166cfac47274>\u001b[0m in \u001b[0;36mpredict_single_frame\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# print(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# note that we detach the deltas because Faster R-CNN do not backprop through\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# the proposals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mproposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_coder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_bbox_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mproposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_proposals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjectness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_anchors_per_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/_utils.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbox_sum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mrel_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbox_sum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/_utils.py\u001b[0m in \u001b[0;36mdecode_single\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Distance from center to box's corner.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mc_to_c_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_ctr_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpred_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mc_to_c_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_ctr_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpred_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# MENJALANKAN MQTT PUBLISHER \n",
        "run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "239b32bbec4a4694b68d1028b0220079": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29caae1565ee41ffaa689bc3edd01a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb3dfc46c84492ca52331a455aa8bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_52600f544a0b4c14a6497079bd56e924",
            "value": "100%"
          }
        },
        "2c0fd2cc5e5e49148ff3decdc99255ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e000f447bed4eb49a672654fd75d737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3643dc5378c414498af6eb70f9407da",
            "placeholder": "​",
            "style": "IPY_MODEL_f41a1f14873e428f89fcc8fe7afaace4",
            "value": " 170M/170M [00:00&lt;00:00, 210MB/s]"
          }
        },
        "2ef43e13169b4d37a9da642d04300ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_239b32bbec4a4694b68d1028b0220079",
            "max": 178090079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36beea8978fb412b90c69e70890aed6d",
            "value": 178090079
          }
        },
        "36beea8978fb412b90c69e70890aed6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52600f544a0b4c14a6497079bd56e924": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f6e58820ec14285839216743bf0710a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29caae1565ee41ffaa689bc3edd01a65",
              "IPY_MODEL_2ef43e13169b4d37a9da642d04300ed5",
              "IPY_MODEL_2e000f447bed4eb49a672654fd75d737"
            ],
            "layout": "IPY_MODEL_2c0fd2cc5e5e49148ff3decdc99255ec"
          }
        },
        "d3643dc5378c414498af6eb70f9407da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41a1f14873e428f89fcc8fe7afaace4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffb3dfc46c84492ca52331a455aa8bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
